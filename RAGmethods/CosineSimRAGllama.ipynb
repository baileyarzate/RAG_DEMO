{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b68efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.auto import partition\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "\n",
    "docs = []\n",
    "doc_folder = r'C:\\Users\\admin\\Documents\\testtxtdir\\pdfdir'\n",
    "for filename in os.listdir(doc_folder):\n",
    "    filepath = os.path.join(doc_folder, filename)\n",
    "    if os.path.isfile(filepath):\n",
    "        elements = partition(filename=filepath)\n",
    "        text = \"\\n\\n\".join([str(el) for el in elements])\n",
    "        docs.append({\"source\": filename, \"content\": text})\n",
    "\n",
    "# Now you have a list of dictionaries with \"source\" and \"content\"\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=15)\n",
    "all_splits = []\n",
    "for doc in docs:\n",
    "    splits = text_splitter.split_text(doc['content'])\n",
    "    for i, split in enumerate(splits):\n",
    "        all_splits.append({\"source\": doc['source'], \"content\": split, \"page\": i+1}) # Assuming page numbers are sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d7325f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d709497-cfff-4638-a0bb-b3de4618ff76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "import pandas as pd\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# Load documents from a local directory\n",
    "#loader = DirectoryLoader(\n",
    "#    r'C:\\Users\\admin\\Documents\\testtxtdir',  # Specify the path to your local directory\n",
    "#)\n",
    "# Load the documents\n",
    "#data = loader.load()\n",
    "\n",
    "data = TextLoader(r\"C:\\Users\\admin\\Documents\\testtxtdir\\rawtxtdir\\F16_flight_manual.txt\").load()\n",
    "# Split the documents into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=15)\n",
    "all_splits = text_splitter.split_documents(data)\n",
    "model = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=model)\n",
    "llm = ChatOllama(model=\"llama3.1:8b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "186f678e-3c23-44a4-9325-6e99d3a39f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RAG(user_prompt, llm, vectorstore, top_k_hits = 3, stream = False, source_summaries = False):\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    # For conciseness add: Use three sentences maximum and keep the answer concise.\n",
    "    RAG_TEMPLATE = \"\"\"\n",
    "    You are an assistant for question-answering tasks. \n",
    "    Use the following pieces of retrieved context to answer the question. \n",
    "    If you don't know the answer, just say that you don't know. \n",
    "    Keep it brief. \n",
    "    \n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "    \n",
    "    Answer the following question:\n",
    "    \n",
    "    {question}\"\"\"\n",
    "    \n",
    "    rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)\n",
    "    \n",
    "    retriever = vectorstore.as_retriever()\n",
    "    \n",
    "    qa_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | rag_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    question = user_prompt\n",
    "    \n",
    "    docs = vectorstore.similarity_search(question, k = top_k_hits)\n",
    "    if not docs:\n",
    "        return \"No relevant documents found\", pd.DataFrame()\n",
    "    \n",
    "    sources = []\n",
    "    contents = []\n",
    "    for i in range(len(docs)):\n",
    "        sources.append(docs[i].metadata['source'])\n",
    "        contents.append(docs[i].page_content)\n",
    "        \n",
    "    if source_summaries:\n",
    "        summaries = [llm.invoke(f'summarize this in one sentence. <{doc.page_content}> ').content for doc in docs]\n",
    "        source_df = pd.DataFrame([sources, contents, summaries],index = [\"source\", \"content\", \"short summary\"]).T\n",
    "    else:\n",
    "        source_df = pd.DataFrame([sources, contents],index = [\"source\", \"content\"]).T\n",
    "    \n",
    "    if stream:\n",
    "        for chunk in qa_chain.stream(question):\n",
    "            print(chunk, end=\"\", flush=True)\n",
    "        return '', source_df\n",
    "    else:\n",
    "        result = qa_chain.invoke(question)\n",
    "        return result, source_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2682c3c3-8965-46e4-b67d-dea3858df45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The air refueling process involves precise and detailed planning, where both the tanker and receiver crew must be thoroughly familiar with all aspects of the refueling. The procedure requires coordination between planners and crews to ensure success. During the operation, the tanker boom is controlled by the boom operator, while fuel transfer (pressure, flow, quantity) is normally controlled by the tanker crew. The refueling sequence typically involves a lead receiver, followed by subsequent receivers in a structured formation, with no more than three aircraft on each wing of the tanker.\n",
      "\n",
      "Source information:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\admin\\Documents\\testtxtdir\\F16_flight...</td>\n",
       "      <td>Terminating refueling with partially filled ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\admin\\Documents\\testtxtdir\\F16_flight...</td>\n",
       "      <td>INTRODUCTION\\n\\nThis section contains informat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\admin\\Documents\\testtxtdir\\F16_flight...</td>\n",
       "      <td>8\u000612\u0005\u0005\u0005Change 1\\n\\nPost Air Refueling\\n\\nUpon ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  C:\\Users\\admin\\Documents\\testtxtdir\\F16_flight...   \n",
       "1  C:\\Users\\admin\\Documents\\testtxtdir\\F16_flight...   \n",
       "2  C:\\Users\\admin\\Documents\\testtxtdir\\F16_flight...   \n",
       "\n",
       "                                             content  \n",
       "0  Terminating refueling with partially filled ta...  \n",
       "1  INTRODUCTION\\n\\nThis section contains informat...  \n",
       "2  8\u000612\u0005\u0005\u0005Change 1\\n\\nPost Air Refueling\\n\\nUpon ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt = \"Tell me about the air refueling process\"\n",
    "\n",
    "result, sources_df = RAG(user_prompt, llm, vectorstore, stream = True, source_summaries = False, top_k_hits = 3)\n",
    "\n",
    "print(result)\n",
    "print('\\nSource information:')\n",
    "sources_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce4bce2d-556e-4d2f-9cc6-d3e7668d9923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004000186920166016,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Split strings",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec6cc99362346719cc57095879e7d7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003999471664428711,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "BM25S Count Tokens",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52938d3e3dfe4361ab74d42cdd6065cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Count Tokens:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003999948501586914,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "BM25S Compute Scores",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee9bb7210d1a466ea8eaea314976ec86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Compute Scores:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004001617431640625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Split strings",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50bff92304fb44b684b70585323a17af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0039997100830078125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "BM25S Retrieve",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "879ea6ee043046adaa4b1cd642f03976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Retrieve:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['cats and dogs are pets.'\n",
      "  'cats and dogs are pet animals though I prefer dogs. Dogs obey our commands, can be trained easily and play with us all the time.']] [[0.3659254  0.32038802]]\n"
     ]
    }
   ],
   "source": [
    "#bm25 method\n",
    "import bm25s\n",
    "\n",
    "# Create your corpus here\n",
    "corpus = [\n",
    "    'cats and dogs are pets.',\n",
    "    'cats and dogs are pet animals though I prefer dogs. Dogs obey our commands, can be trained easily and play with us all the time.',\n",
    "    'And this is the third one.',\n",
    "    'Horses are also pets',\n",
    "]\n",
    "\n",
    "\n",
    "# Tokenize the corpus and only keep the ids (faster and saves memory)\n",
    "corpus_tokens = bm25s.tokenize(corpus, stopwords=\"en\")\n",
    "\n",
    "# Create the BM25 model and index the corpus\n",
    "retriever = bm25s.BM25()\n",
    "retriever.index(corpus_tokens)\n",
    "\n",
    "# Query the corpus\n",
    "query = \"dogs\"\n",
    "query_tokens = bm25s.tokenize(query)\n",
    "\n",
    "# Get top-k results as a tuple of (doc ids, scores). Both are arrays of shape (n_queries, k)\n",
    "results, scores = retriever.retrieve(query_tokens, corpus=corpus, k=2)\n",
    "print(results, scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
