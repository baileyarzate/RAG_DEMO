{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d709497-cfff-4638-a0bb-b3de4618ff76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "import pandas as pd\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "# Load documents from a local directory\n",
    "loader = DirectoryLoader(\n",
    "    r'C:\\Users\\admin\\Documents\\testtxtdir',  # Specify the path to your local directory\n",
    ")\n",
    "\n",
    "# Load the documents\n",
    "data = loader.load()\n",
    "\n",
    "# Split the documents into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=15)\n",
    "all_splits = text_splitter.split_documents(data)\n",
    "model = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=model)\n",
    "llm = ChatOllama(model=\"llama3.1:8b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "186f678e-3c23-44a4-9325-6e99d3a39f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RAG(user_prompt, llm, vectorstore, top_k_hits = 3, stream = False, source_summaries = False):\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    # For conciseness add: Use three sentences maximum and keep the answer concise.\n",
    "    RAG_TEMPLATE = \"\"\"\n",
    "    You are an assistant for question-answering tasks. \n",
    "    Use the following pieces of retrieved context to answer the question. \n",
    "    If you don't know the answer, just say that you don't know. \n",
    "    Keep it brief. \n",
    "    \n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "    \n",
    "    Answer the following question:\n",
    "    \n",
    "    {question}\"\"\"\n",
    "    \n",
    "    rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)\n",
    "    \n",
    "    retriever = vectorstore.as_retriever()\n",
    "    \n",
    "    qa_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | rag_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    question = user_prompt\n",
    "    \n",
    "    docs = vectorstore.similarity_search(question, k = top_k_hits)\n",
    "    if not docs:\n",
    "        return \"No relevant documents found\", pd.DataFrame()\n",
    "    \n",
    "    sources = []\n",
    "    contents = []\n",
    "    for i in range(len(docs)):\n",
    "        sources.append(docs[i].metadata['source'])\n",
    "        contents.append(docs[i].page_content)\n",
    "        \n",
    "    if source_summaries:\n",
    "        summaries = [llm.invoke(f'summarize this in one sentence. <{doc.page_content}> ').content for doc in docs]\n",
    "        source_df = pd.DataFrame([sources, contents, summaries],index = [\"source\", \"content\", \"short summary\"]).T\n",
    "    else:\n",
    "        source_df = pd.DataFrame([sources, contents],index = [\"source\", \"content\"]).T\n",
    "    \n",
    "    if stream:\n",
    "        for chunk in qa_chain.stream(question):\n",
    "            print(chunk, end=\"\", flush=True)\n",
    "        return '', source_df\n",
    "    else:\n",
    "        result = qa_chain.invoke(question)\n",
    "        return result, source_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2682c3c3-8965-46e4-b67d-dea3858df45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The air refueling process involves precise and detailed planning, where both the tanker and receiver crew must be thoroughly familiar with all aspects of the refueling. The procedure requires coordination between planners and crews to ensure success. During the operation, the tanker boom is controlled by the boom operator, while fuel transfer (pressure, flow, quantity) is normally controlled by the tanker crew. The refueling sequence typically involves a lead receiver, followed by subsequent receivers in a structured formation, with no more than three aircraft on each wing of the tanker.\n",
      "\n",
      "Source information:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\admin\\Documents\\testtxtdir\\F16_flight...</td>\n",
       "      <td>Terminating refueling with partially filled ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\admin\\Documents\\testtxtdir\\F16_flight...</td>\n",
       "      <td>INTRODUCTION\\n\\nThis section contains informat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\admin\\Documents\\testtxtdir\\F16_flight...</td>\n",
       "      <td>8\u000612\u0005\u0005\u0005Change 1\\n\\nPost Air Refueling\\n\\nUpon ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  C:\\Users\\admin\\Documents\\testtxtdir\\F16_flight...   \n",
       "1  C:\\Users\\admin\\Documents\\testtxtdir\\F16_flight...   \n",
       "2  C:\\Users\\admin\\Documents\\testtxtdir\\F16_flight...   \n",
       "\n",
       "                                             content  \n",
       "0  Terminating refueling with partially filled ta...  \n",
       "1  INTRODUCTION\\n\\nThis section contains informat...  \n",
       "2  8\u000612\u0005\u0005\u0005Change 1\\n\\nPost Air Refueling\\n\\nUpon ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt = \"Tell me about the air refueling process\"\n",
    "\n",
    "result, sources_df = RAG(user_prompt, llm, vectorstore, stream = True, source_summaries = False, top_k_hits = 3)\n",
    "\n",
    "print(result)\n",
    "print('\\nSource information:')\n",
    "sources_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4bce2d-556e-4d2f-9cc6-d3e7668d9923",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
