{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from unstructured.partition.auto import partition\n",
    "from langchain.schema import Document\n",
    "import os\n",
    "import pandas as pd\n",
    "#from langchain.document_loaders import DirectoryLoader\n",
    "#from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# 1. Document Loading and Page Tracking\n",
    "docs = []\n",
    "doc_folder = r'C:\\Users\\admin\\Documents\\LLM\\B1-B data'\n",
    "for filename in os.listdir(doc_folder):\n",
    "    filepath = os.path.join(doc_folder, filename)\n",
    "    if os.path.isfile(filepath):\n",
    "        elements = partition(filename=filepath)\n",
    "        for i, element in enumerate(elements):\n",
    "            # Extract text content and page information\n",
    "            text = str(element) \n",
    "            page_number = element.metadata.page_number if element.metadata.page_number else 'N/A'  # Extract page info\n",
    "            docs.append({\"source\": filename, \"content\": text, \"page\": page_number})\n",
    "\n",
    "# 2. Chunking while Preserving Page Information\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=4096, chunk_overlap=300)\n",
    "all_splits = []\n",
    "current_chunk = \"\"\n",
    "current_metadata = {} \n",
    "\n",
    "for doc in docs:\n",
    "    splits = text_splitter.split_text(doc['content'])\n",
    "    for split in splits:\n",
    "        if len(current_chunk) + len(split) <= 4096: \n",
    "            current_chunk += split + \" \" # Add to the current chunk\n",
    "            current_metadata = {\"source\": doc['source'], \"page\": doc['page']} \n",
    "        else:\n",
    "            all_splits.append(Document(page_content=current_chunk, metadata=current_metadata))\n",
    "            current_chunk = split + \" \"\n",
    "            current_metadata = {\"source\": doc['source'], \"page\": doc['page']}\n",
    "\n",
    "# Append the last chunk\n",
    "if current_chunk:\n",
    "    all_splits.append(Document(page_content=current_chunk, metadata=current_metadata)) \n",
    "\n",
    "# 3. Vectorstore and Retriever Setup\n",
    "model = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=model)\n",
    "llm = ChatOllama(model=\"llama3.1:8b\")  # Or your preferred LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. RAG Function (Incorporating Contextual Compression)\n",
    "def RAG(user_prompt, llm, vectorstore, stream=False, source_summaries=False, retrieval = 'contextual', top_k_hits = 5):\n",
    "    # retrieval methods: contextual, cosine_similarity, both\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(\n",
    "            f\"Source: {doc.metadata['source']} - Page: {doc.metadata.get('page', 'N/A')}\\n\\n{doc.page_content}\" \n",
    "            for doc in docs\n",
    "        )\n",
    "\n",
    "    RAG_TEMPLATE = \"\"\"\n",
    "        This is a chat between a user and an artificial intelligence assistant. \n",
    "        The assistant gives helpful, detailed, and polite answers to the user's questions based on the context. \n",
    "        With regard to the source, 'embedded' means the content was embedded in the PDF file, and 'predicted' means the content was generated by an OCR model. \n",
    "        As such, there may be inaccuracies (spelling, spacing, missing symbols, etc.) in the predicted content, the embedded content, and the actual content. \n",
    "        The assistant should also indicate when the answer cannot be found in the context.\n",
    "\n",
    "        When providing an answer, cite the source document and page number in parentheses where you found the relevant information, like this: ([Source: document_name, Page 1]). \n",
    "        If multiple sources contain relevant information, cite them all.\n",
    "\n",
    "        <context>\n",
    "        {context}\n",
    "        </context>\n",
    "\n",
    "        Answer the following question:\n",
    "\n",
    "        {question}\"\"\"\n",
    "    question = user_prompt\n",
    "    rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    if retrieval == 'contextual' or retrieval == 'both':\n",
    "        compressor = LLMChainExtractor.from_llm(llm) \n",
    "        compression_retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=compressor, base_retriever=retriever\n",
    "        )\n",
    "        qa_chain = (\n",
    "            {\"context\": compression_retriever | format_docs, \"question\": RunnablePassthrough()} \n",
    "            | rag_prompt\n",
    "            | llm\n",
    "            | StrOutputParser() \n",
    "        )\n",
    "        \n",
    "        docs = compression_retriever.invoke(question)  # Invoke on the question \n",
    "    if retrieval == 'cosine_similarity' or retrieval == 'both':\n",
    "        if retrieval != 'both':\n",
    "            qa_chain = (\n",
    "                {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "                | rag_prompt\n",
    "                | llm\n",
    "                | StrOutputParser()\n",
    "            )\n",
    "        if retrieval == 'both':\n",
    "            docs.extend(vectorstore.similarity_search(question, k = top_k_hits))\n",
    "        else:\n",
    "            docs = vectorstore.similarity_search(question, k = top_k_hits)\n",
    "\n",
    "    if not docs:\n",
    "        return \"No relevant documents found\", pd.DataFrame()\n",
    "\n",
    "    source_data = []\n",
    "    for doc in docs:\n",
    "        source_data.append({\n",
    "            \"source\": doc.metadata['source'], \n",
    "            \"page\": doc.metadata.get('page', 'N/A'),\n",
    "            \"content\": doc.page_content \n",
    "        })\n",
    "\n",
    "    if source_summaries:\n",
    "        summaries = [llm.invoke(f'Summarize this in one or two sentences. Only state main point, nothing else. <{doc.page_content}> ').content for doc in docs]\n",
    "        source_df = pd.DataFrame(source_data)\n",
    "        source_df[\"short summary\"] = summaries\n",
    "    else:\n",
    "        source_df = pd.DataFrame(source_data)\n",
    "\n",
    "    if stream:\n",
    "        for chunk in qa_chain.stream(question):\n",
    "            print(chunk, end=\"\", flush=True)\n",
    "        return '', source_df\n",
    "    else:\n",
    "        result = qa_chain.invoke(question)\n",
    "        return result, source_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, the findings of the human factors study on Helmet Mounted Displays (HMD) for B-1B pilots can be summarized as follows:\n",
      "\n",
      "The HMD was considered a useful tool in improving situational awareness (SA) for B-1B pilots, particularly in providing navigation information and steering arrows directly to the Designated Missions Points (DMPIs). The ability to glance to the right or left and see the DMPIs was deemed very useful.\n",
      "\n",
      "However, the study also highlighted some limitations and areas for improvement:\n",
      "\n",
      "* The HMD's symbology required readdressing, particularly in relation to the JDAM footprint display.\n",
      "* The LAR depiction needed to be higher in the field of view.\n",
      "* Symbology was too small at the top and not all-inclusive.\n",
      "* Head movement was increased with the current design, making it difficult to see threats at 3+9 o'clock positions.\n",
      "\n",
      "The study's participants generally agreed that a properly designed HMD would be beneficial for both JDAM releases and threat avoidance. Some suggestions for improvement included:\n",
      "\n",
      "* Improving the size and clarity of the device's image.\n",
      "* Providing better steering information directly to the DMPIs.\n",
      "* Enhancing navigation information, particularly in relation to target steering.\n",
      "* Ensuring compatibility with Night Vision Goggles (NVGs).\n",
      "\n",
      "Overall, while the HMD showed promise in improving SA for B-1B pilots, further development and refinement were deemed necessary.\n",
      "\n",
      "Source information:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>page</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Human Factors Study of a Helmet Mounted Disp...</td>\n",
       "      <td>11</td>\n",
       "      <td>* 1.3 New smart weapons and advanced avionics ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Human Factors Study of a Helmet Mounted Disp...</td>\n",
       "      <td>23</td>\n",
       "      <td>&gt; Question: Summarize the findings of the huma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Human Factors Study of a Helmet Mounted Disp...</td>\n",
       "      <td>35</td>\n",
       "      <td>Here are the extracted relevant parts of the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Human Factors Study of a Helmet Mounted Disp...</td>\n",
       "      <td>30</td>\n",
       "      <td>The extracted part of the context is:\\n\\n* The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Human Factors Study of a Helmet Mounted Disp...</td>\n",
       "      <td>11</td>\n",
       "      <td>JHMCS LAR LCD MRAD NM SAM TTG UTTR VSD LIST OF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A Human Factors Study of a Helmet Mounted Disp...</td>\n",
       "      <td>23</td>\n",
       "      <td>7 Totally Acceptable 6 Very Acceptable 5 Somew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A Human Factors Study of a Helmet Mounted Disp...</td>\n",
       "      <td>35</td>\n",
       "      <td>8. Were all the HMD Lines clear and distinct? ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  page  \\\n",
       "0  A Human Factors Study of a Helmet Mounted Disp...    11   \n",
       "1  A Human Factors Study of a Helmet Mounted Disp...    23   \n",
       "2  A Human Factors Study of a Helmet Mounted Disp...    35   \n",
       "3  A Human Factors Study of a Helmet Mounted Disp...    30   \n",
       "4  A Human Factors Study of a Helmet Mounted Disp...    11   \n",
       "5  A Human Factors Study of a Helmet Mounted Disp...    23   \n",
       "6  A Human Factors Study of a Helmet Mounted Disp...    35   \n",
       "\n",
       "                                             content  \n",
       "0  * 1.3 New smart weapons and advanced avionics ...  \n",
       "1  > Question: Summarize the findings of the huma...  \n",
       "2  Here are the extracted relevant parts of the c...  \n",
       "3  The extracted part of the context is:\\n\\n* The...  \n",
       "4  JHMCS LAR LCD MRAD NM SAM TTG UTTR VSD LIST OF...  \n",
       "5  7 Totally Acceptable 6 Very Acceptable 5 Somew...  \n",
       "6  8. Were all the HMD Lines clear and distinct? ...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt = \"Summarize the findings of the human factors study on Helmet Mounted Displays (HMD) for B-1B pilots.\"\n",
    "result, sources_df = RAG(user_prompt, llm, vectorstore, stream=True, source_summaries=False, retrieval = 'both', top_k_hits = 3) \n",
    "print(result)\n",
    "print('\\nSource information:')\n",
    "sources_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
